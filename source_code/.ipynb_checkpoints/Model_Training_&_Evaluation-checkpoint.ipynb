{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"14ed097c-1107-45dd-b25c-4b1761ef1067","cell_type":"code","source":"#!pip install datasets torch ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T15:43:31.217237Z","iopub.execute_input":"2025-03-21T15:43:31.217576Z","iopub.status.idle":"2025-03-21T15:43:31.221129Z","shell.execute_reply.started":"2025-03-21T15:43:31.217544Z","shell.execute_reply":"2025-03-21T15:43:31.220325Z"}},"outputs":[],"execution_count":2},{"id":"532d903d-7314-4b4d-9edd-072079f6c91b","cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T17:09:13.593231Z","iopub.execute_input":"2025-03-24T17:09:13.593415Z","iopub.status.idle":"2025-03-24T17:09:13.597401Z","shell.execute_reply.started":"2025-03-24T17:09:13.593395Z","shell.execute_reply":"2025-03-24T17:09:13.596472Z"}},"outputs":[],"execution_count":1},{"id":"0760698e-0f28-4262-9515-21169fc9fb9b","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:33:59.890389Z","iopub.execute_input":"2025-03-21T18:33:59.890664Z","iopub.status.idle":"2025-03-21T18:34:02.261961Z","shell.execute_reply.started":"2025-03-21T18:33:59.890642Z","shell.execute_reply":"2025-03-21T18:34:02.261331Z"}},"outputs":[],"execution_count":2},{"id":"92df3aee-f6d6-405d-8574-334422b61f78","cell_type":"code","source":"movies = load_dataset(\"ExecuteAutomation/ImdbMovieDataSet\")\nmusic = load_dataset(\"maharshipandya/spotify-tracks-dataset\")\nbooks = load_dataset(\"Eitanli/goodreads\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:34:06.515961Z","iopub.execute_input":"2025-03-21T18:34:06.516405Z","iopub.status.idle":"2025-03-21T18:34:15.066687Z","shell.execute_reply.started":"2025-03-21T18:34:06.516381Z","shell.execute_reply":"2025-03-21T18:34:15.065886Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/850 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c212799f7684575bd4934d2db5f8a5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imdb_movies.csv:   0%|          | 0.00/6.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab2a144453a4ab2aff5b75f24fce36e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f58a9d69d341eca162b32c46ce9ba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a2fc7a3e7fc4b8883e48465b78400c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset.csv:   0%|          | 0.00/20.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b28ff3c4e324ab28a9838289b4f0005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/114000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c07bf430c07437ba545cb307feed89f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd35782c10d44e48b1237cc5a250cb0"}},"metadata":{}},{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"goodreads_data.csv:   0%|          | 0.00/11.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"406a1b0aaf144cc895b1792f6cdaca62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69740e66c501479db7cafecf31af0fe6"}},"metadata":{}}],"execution_count":3},{"id":"b274dda1-70d5-47b5-9dfa-82002c0bab8c","cell_type":"code","source":"movies_df = movies['train'].to_pandas()\nmusic_df = music['train'].to_pandas()\nbooks_df = books['train'].to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:34:19.872630Z","iopub.execute_input":"2025-03-21T18:34:19.872973Z","iopub.status.idle":"2025-03-21T18:34:20.019089Z","shell.execute_reply.started":"2025-03-21T18:34:19.872950Z","shell.execute_reply":"2025-03-21T18:34:20.018166Z"}},"outputs":[],"execution_count":4},{"id":"d16bb941-b116-4ad6-ae67-248d334c1945","cell_type":"code","source":"print(movies_df.columns)\nprint(music_df.columns)\nprint(books_df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:34:22.811532Z","iopub.execute_input":"2025-03-21T18:34:22.811870Z","iopub.status.idle":"2025-03-21T18:34:22.817180Z","shell.execute_reply.started":"2025-03-21T18:34:22.811841Z","shell.execute_reply":"2025-03-21T18:34:22.816325Z"}},"outputs":[{"name":"stdout","text":"Index(['names', 'date_x', 'score', 'genre', 'overview', 'crew', 'orig_title',\n       'status', 'orig_lang', 'budget_x', 'revenue', 'country'],\n      dtype='object')\nIndex(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name',\n       'popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n       'track_genre'],\n      dtype='object')\nIndex(['Unnamed: 0', 'Book', 'Author', 'Description', 'Genres', 'Avg_Rating',\n       'Num_Ratings', 'URL'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":5},{"id":"e62feff6-a507-4409-ae59-6e5727cd4f59","cell_type":"code","source":"# Assign unique Item_IDs\nmovies_df[\"Item_ID\"] = \"Movie_\" + movies_df[\"names\"].astype(str)\nmusic_df[\"Item_ID\"] = \"Music_\" + music_df[\"track_id\"].astype(str)\nbooks_df[\"Item_ID\"] = \"Book_\" + books_df[\"Book\"].astype(str)\n\n# Standardizing Columns\nmovies_df = movies_df[[\"Item_ID\", \"orig_title\", \"genre\", \"overview\", \"score\", \"crew\", \"date_x\"]]\nmusic_df = music_df[[\"Item_ID\", \"track_name\", \"track_genre\", \"popularity\", \"artists\"]]\nbooks_df = books_df[[\"Item_ID\", \"Book\", \"Genres\", \"Description\", \"Avg_Rating\", \"Author\"]]\n\n# Rename for consistency\nmovies_df.rename(columns={\"orig_title\": \"Title\", \"genre\": \"Genre\", \"overview\": \"Description\", \"score\": \"Popularity\", \"crew\": \"Creator\", \"date_x\": \"Timestamp\"}, inplace=True)\nmusic_df.rename(columns={\"track_name\": \"Title\", \"track_genre\": \"Genre\", \"popularity\": \"Popularity\", \"artists\": \"Creator\"}, inplace=True)\nbooks_df.rename(columns={\"Book\": \"Title\", \"Genres\": \"Genre\", \"Description\": \"Description\", \"Avg_Rating\": \"Popularity\", \"Author\": \"Creator\"}, inplace=True)\n\n# Add Item_Type\nmovies_df[\"Item_Type\"] = \"Movie\"\nmusic_df[\"Item_Type\"] = \"Music\"\nbooks_df[\"Item_Type\"] = \"Book\"\n\n# Handle missing timestamps (generate random timestamps)\nmovies_df[\"Timestamp\"] = pd.to_datetime(movies_df[\"Timestamp\"], errors=\"coerce\")\nmusic_df[\"Timestamp\"] = pd.to_datetime(\"2024-03-17\")  # Static timestamp\nbooks_df[\"Timestamp\"] = pd.to_datetime(\"2024-03-17\")  # Static timestamp\n\n# Combine datasets\nmerged_df = pd.concat([movies_df, music_df, books_df], ignore_index=True)\n\n# Save preprocessed dataset\nmerged_df.to_csv(\"session_data.csv\", index=False)\n\nprint(merged_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:34:28.635850Z","iopub.execute_input":"2025-03-21T18:34:28.636253Z","iopub.status.idle":"2025-03-21T18:34:29.588861Z","shell.execute_reply.started":"2025-03-21T18:34:28.636218Z","shell.execute_reply":"2025-03-21T18:34:29.587951Z"}},"outputs":[{"name":"stdout","text":"                             Item_ID                        Title  \\\n0                    Movie_Creed III                    Creed III   \n1     Movie_Avatar: The Way of Water     Avatar: The Way of Water   \n2  Movie_The Super Mario Bros. Movie  The Super Mario Bros. Movie   \n3                      Movie_Mummies                       Momias   \n4                    Movie_Supercell                    Supercell   \n\n                                           Genre  \\\n0                                  Drama, Action   \n1             Science Fiction, Adventure, Action   \n2  Animation, Adventure, Family, Fantasy, Comedy   \n3  Animation, Comedy, Family, Adventure, Fantasy   \n4                                         Action   \n\n                                         Description  Popularity  \\\n0  After dominating the boxing world, Adonis Cree...        73.0   \n1  Set more than a decade after the events of the...        78.0   \n2  While working underground to fix a water main,...        76.0   \n3  Through a series of unfortunate events, three ...        70.0   \n4  Good-hearted teenager William always lived in ...        61.0   \n\n                                             Creator  Timestamp Item_Type  \n0  Michael B. Jordan, Adonis Creed, Tessa Thompso... 2023-03-02     Movie  \n1  Sam Worthington, Jake Sully, Zoe Saldaña, Neyt... 2022-12-15     Movie  \n2  Chris Pratt, Mario (voice), Anya Taylor-Joy, P... 2023-04-05     Movie  \n3  Óscar Barberán, Thut (voice), Ana Esther Albor... 2023-01-05     Movie  \n4  Skeet Ulrich, Roy Cameron, Anne Heche, Dr Quin... 2023-03-17     Movie  \n","output_type":"stream"}],"execution_count":6},{"id":"c8227284-83fb-4cb5-bee5-23449522e1d7","cell_type":"code","source":"# Simulating user sessions\nsession_ids = np.random.randint(1000, 5000, size=len(merged_df))\naction_types = np.random.choice([\"Clicked\", \"Searched\", \"Scrolled\"], size=len(merged_df))\n\nmerged_df[\"Session_ID\"] = session_ids\nmerged_df[\"Action_Type\"] = action_types\n\n# Save session-based data\nmerged_df.to_csv(\"session_events.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:34:38.045773Z","iopub.execute_input":"2025-03-21T18:34:38.046053Z","iopub.status.idle":"2025-03-21T18:34:38.963288Z","shell.execute_reply.started":"2025-03-21T18:34:38.046034Z","shell.execute_reply":"2025-03-21T18:34:38.962612Z"}},"outputs":[],"execution_count":7},{"id":"c1b80706-ceaa-4e12-afb4-807791e3cd2f","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Load session data\ndata = pd.read_csv(\"session_events.csv\")\n\n# Convert Item_IDs into unique numerical values\nitem_vocab = {item: idx for idx, item in enumerate(set(data[\"Item_ID\"]))}\ninv_vocab = {idx: item for item, idx in item_vocab.items()}\n\n# Convert sessions into numerical sequences\nsessions = data.groupby(\"Session_ID\")[\"Item_ID\"].apply(lambda x: [item_vocab[i] for i in x]).tolist()\n\n# Dataset Class\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass SessionDataset(Dataset):\n    def __init__(self, sessions, max_length=50):\n        self.sessions = sessions\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.sessions)\n\n    def __getitem__(self, idx):\n        session = self.sessions[idx]\n        session_tensor = torch.tensor(session, dtype=torch.long)\n\n        # Pad sequences to the max length\n        if len(session_tensor) < self.max_length:\n            pad_size = self.max_length - len(session_tensor)\n            session_tensor = torch.cat([session_tensor, torch.zeros(pad_size, dtype=torch.long)])\n\n        return session_tensor[:-1], session_tensor[1:]  # Input & Target\n\n# Collate function to pad sequences dynamically in the DataLoader\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n    targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n\n# Define GRU Model\nclass GRU4Rec(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n        super(GRU4Rec, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.gru(x)\n        return self.fc(out)\n\n# Training Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndataset = SessionDataset(sessions)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n\nmodel = GRU4Rec(len(item_vocab)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n\nfor epoch in range(50):\n    for batch in dataloader:\n        #inputs, targets = batch\n        inputs, targets = batch\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs.view(-1, len(item_vocab)), targets.view(-1))\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n#torch.save(model.state_dict(), \"session_rec_model.pth\")\ntorch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), \"session_rec_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:34:42.808348Z","iopub.execute_input":"2025-03-21T18:34:42.808626Z","iopub.status.idle":"2025-03-21T18:51:36.082218Z","shell.execute_reply.started":"2025-03-21T18:34:42.808604Z","shell.execute_reply":"2025-03-21T18:51:36.081238Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-8-c741148c7e68>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n<ipython-input-8-c741148c7e68>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 7.690988540649414\nEpoch 2, Loss: 7.596072673797607\nEpoch 3, Loss: 7.072775840759277\nEpoch 4, Loss: 6.372457027435303\nEpoch 5, Loss: 5.28287935256958\nEpoch 6, Loss: 4.004252910614014\nEpoch 7, Loss: 2.8613224029541016\nEpoch 8, Loss: 1.953985571861267\nEpoch 9, Loss: 1.0319585800170898\nEpoch 10, Loss: 0.7213608622550964\nEpoch 11, Loss: 0.41617482900619507\nEpoch 12, Loss: 0.25872746109962463\nEpoch 13, Loss: 0.20532339811325073\nEpoch 14, Loss: 0.11697680503129959\nEpoch 15, Loss: 0.08248290419578552\nEpoch 16, Loss: 0.08017588406801224\nEpoch 17, Loss: 0.05788752809166908\nEpoch 18, Loss: 0.044767845422029495\nEpoch 19, Loss: 0.038895055651664734\nEpoch 20, Loss: 0.03399191424250603\nEpoch 21, Loss: 0.03168043494224548\nEpoch 22, Loss: 0.02802925743162632\nEpoch 23, Loss: 0.028693964704871178\nEpoch 24, Loss: 0.02787163481116295\nEpoch 25, Loss: 0.02221776731312275\nEpoch 26, Loss: 0.017336327582597733\nEpoch 27, Loss: 0.01764662377536297\nEpoch 28, Loss: 0.018843399360775948\nEpoch 29, Loss: 0.013296118937432766\nEpoch 30, Loss: 0.014882288873195648\nEpoch 31, Loss: 0.012950303964316845\nEpoch 32, Loss: 0.01074859406799078\nEpoch 33, Loss: 0.011737334541976452\nEpoch 34, Loss: 0.012340893037617207\nEpoch 35, Loss: 0.015351041220128536\nEpoch 36, Loss: 0.011723592877388\nEpoch 37, Loss: 0.010426000691950321\nEpoch 38, Loss: 0.006986949592828751\nEpoch 39, Loss: 0.00940189603716135\nEpoch 40, Loss: 0.006995514966547489\nEpoch 41, Loss: 0.006028181407600641\nEpoch 42, Loss: 0.010025842115283012\nEpoch 43, Loss: 0.010780985467135906\nEpoch 44, Loss: 0.005456212442368269\nEpoch 45, Loss: 0.012309588491916656\nEpoch 46, Loss: 0.007568041794002056\nEpoch 47, Loss: 0.005075974855571985\nEpoch 48, Loss: 0.007050555665045977\nEpoch 49, Loss: 0.008526364341378212\nEpoch 50, Loss: 0.009745242074131966\n","output_type":"stream"}],"execution_count":8},{"id":"e4c6b30b-275e-452d-93e2-5b5c3ae83d26","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom torch.nn.utils.rnn import pad_sequence\n\n# Load session data\ndata = pd.read_csv(\"session_events.csv\")\n\n# Convert Item_IDs into unique numerical values\nitem_vocab = {item: idx for idx, item in enumerate(set(data[\"Item_ID\"]))}\ninv_vocab = {idx: item for item, idx in item_vocab.items()}\n\n# Convert sessions into numerical sequences\nsessions = data.groupby(\"Session_ID\")[\"Item_ID\"].apply(lambda x: [item_vocab[i] for i in x]).tolist()\n\n# Dataset Class\nclass SessionDataset(Dataset):\n    def __init__(self, sessions, max_length=50):\n        self.sessions = sessions\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.sessions)\n\n    def __getitem__(self, idx):\n        session = self.sessions[idx]\n        session_tensor = torch.tensor(session, dtype=torch.long)\n\n        # Pad sequences to the max length\n        if len(session_tensor) < self.max_length:\n            pad_size = self.max_length - len(session_tensor)\n            session_tensor = torch.cat([session_tensor, torch.zeros(pad_size, dtype=torch.long)])\n\n        return session_tensor[:-1], session_tensor[1:]  # Input & Target\n\n# Collate function to pad sequences dynamically in the DataLoader\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n    targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n# Define GRU Model\nclass GRU4Rec(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n        super(GRU4Rec, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.gru(x)\n        return self.fc(out)\n\n# Training Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndataset = SessionDataset(sessions)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n\nmodel = GRU4Rec(len(item_vocab)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n\n# Early Stopping Parameters\npatience = 5  # Number of epochs to wait before stopping\nbest_loss = float('inf')\nepochs_no_improve = 0\nearly_stop = False\n\nfor epoch in range(50):\n    epoch_loss = 0\n    for batch in dataloader:\n        inputs, targets = batch\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs.view(-1, len(item_vocab)), targets.view(-1).long())\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    epoch_loss /= len(dataloader)\n    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}\")\n\n    # Early Stopping Logic\n    if epoch_loss < best_loss:\n        best_loss = epoch_loss\n        epochs_no_improve = 0\n        # Save best model\n        torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), \"best_session_rec_model.pth\")\n    else:\n        epochs_no_improve += 1\n        print(f\"No improvement for {epochs_no_improve}/{patience} epochs.\")\n\n    if epochs_no_improve >= patience:\n        print(\"Early stopping triggered!\")\n        early_stop = True\n        break  # Stop training\n\n# Save final model\ntorch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), \"session_rec_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:54:11.360423Z","iopub.execute_input":"2025-03-21T18:54:11.360782Z","iopub.status.idle":"2025-03-21T19:11:32.969220Z","shell.execute_reply.started":"2025-03-21T18:54:11.360754Z","shell.execute_reply":"2025-03-21T19:11:32.968227Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-10-f2480953a093>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n<ipython-input-10-f2480953a093>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 8.307071125696575\nEpoch 2, Loss: 7.65139435208033\nEpoch 3, Loss: 7.225096967485216\nEpoch 4, Loss: 6.392066531711155\nEpoch 5, Loss: 5.274069975292872\nEpoch 6, Loss: 4.047372151934911\nEpoch 7, Loss: 2.8272931954217335\nEpoch 8, Loss: 1.7609415338152932\nEpoch 9, Loss: 1.0468707964533852\nEpoch 10, Loss: 0.6365305544838072\nEpoch 11, Loss: 0.3960812318892706\nEpoch 12, Loss: 0.2561607233115605\nEpoch 13, Loss: 0.1735328539969429\nEpoch 14, Loss: 0.12308307441454085\nEpoch 15, Loss: 0.09184038166015868\nEpoch 16, Loss: 0.07152377128128022\nEpoch 17, Loss: 0.05786299740984326\nEpoch 18, Loss: 0.04808862211685332\nEpoch 19, Loss: 0.0411058192451795\nEpoch 20, Loss: 0.03562455198594502\nEpoch 21, Loss: 0.03134127413587911\nEpoch 22, Loss: 0.027880316068019186\nEpoch 23, Loss: 0.02512658458380472\nEpoch 24, Loss: 0.022715698277193403\nEpoch 25, Loss: 0.02078732555466039\nEpoch 26, Loss: 0.019079701590632634\nEpoch 27, Loss: 0.017627021519555933\nEpoch 28, Loss: 0.016315578970880734\nEpoch 29, Loss: 0.015163679148942705\nEpoch 30, Loss: 0.01414240003814773\nEpoch 31, Loss: 0.013237946311987582\nEpoch 32, Loss: 0.012442565626568265\nEpoch 33, Loss: 0.011717579637964567\nEpoch 34, Loss: 0.011094338024064662\nEpoch 35, Loss: 0.010450052393097726\nEpoch 36, Loss: 0.009911512985589012\nEpoch 37, Loss: 0.009392340283190448\nEpoch 38, Loss: 0.008968864892801595\nEpoch 39, Loss: 0.008532174848138339\nEpoch 40, Loss: 0.008135444565957028\nEpoch 41, Loss: 0.0077609774316587145\nEpoch 42, Loss: 0.007484903588654503\nEpoch 43, Loss: 0.007157610093672124\nEpoch 44, Loss: 0.006884828047265136\nEpoch 45, Loss: 0.006573760312878423\nEpoch 46, Loss: 0.006347248042445807\nEpoch 47, Loss: 0.006141512832116513\nEpoch 48, Loss: 0.005926008572772382\nEpoch 49, Loss: 0.005714294848047079\nEpoch 50, Loss: 0.005526850683732875\n","output_type":"stream"}],"execution_count":10},{"id":"80dbdd5e-c19f-4964-aae7-da68b0614b5b","cell_type":"code","source":"# Load model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GRU4Rec(len(item_vocab)).to(device)\n\n# Load best trained weights\nmodel.load_state_dict(torch.load(\"best_session_rec_model.pth\", map_location=device))\nmodel.eval()  # Set model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:13:00.498082Z","iopub.execute_input":"2025-03-21T19:13:00.498363Z","iopub.status.idle":"2025-03-21T19:13:01.060854Z","shell.execute_reply.started":"2025-03-21T19:13:00.498340Z","shell.execute_reply":"2025-03-21T19:13:01.059982Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-11-962d09d94511>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"best_session_rec_model.pth\", map_location=device))\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"GRU4Rec(\n  (embedding): Embedding(109272, 128)\n  (gru): GRU(128, 256, batch_first=True)\n  (fc): Linear(in_features=256, out_features=109272, bias=True)\n)"},"metadata":{}}],"execution_count":11},{"id":"45c35288-0ff2-41aa-90c8-ea47a65bc129","cell_type":"code","source":"import torch.nn.functional as F\n\ndef recommend_next_items(session, top_k=5):\n    \"\"\"\n    Given a session (list of Item_IDs), predict the next top-k recommended items.\n    \"\"\"\n    # Convert session items to numerical indices\n    session_numeric = [item_vocab[item] for item in session if item in item_vocab]\n    \n    if not session_numeric:\n        print(\"Error: None of the session items exist in the vocabulary.\")\n        return []\n    \n    # Convert to tensor and move to device\n    session_tensor = torch.tensor(session_numeric, dtype=torch.long).unsqueeze(0).to(device)\n\n    # Get model predictions\n    with torch.no_grad():\n        output = model(session_tensor)  # Shape: (1, seq_len, vocab_size)\n\n    # Get the last output prediction\n    last_item_logits = output[:, -1, :]  # Shape: (1, vocab_size)\n\n    # Convert logits to probabilities\n    probabilities = F.softmax(last_item_logits, dim=-1)\n\n    # Get top-k recommended item indices\n    top_k_indices = torch.topk(probabilities, top_k, dim=-1).indices.squeeze(0).tolist()\n\n    # Convert indices back to Item_IDs\n    recommended_items = [inv_vocab[idx] for idx in top_k_indices]\n\n    return recommended_items\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:13:07.143888Z","iopub.execute_input":"2025-03-21T19:13:07.144173Z","iopub.status.idle":"2025-03-21T19:13:07.150010Z","shell.execute_reply.started":"2025-03-21T19:13:07.144151Z","shell.execute_reply":"2025-03-21T19:13:07.149233Z"}},"outputs":[],"execution_count":12},{"id":"1982af49-289d-4f00-8838-1274cb90e36f","cell_type":"code","source":"# Example session (list of previously interacted Item_IDs)\nexample_session = [\"Movie_Creed III\", \"Movie_Mummies\", \"Movie_Supercell\"]\n\n# Get top 5 recommendations\nrecommendations = recommend_next_items(example_session, top_k=5)\nprint(\"Recommended Items:\", recommendations)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:14:28.749353Z","iopub.execute_input":"2025-03-21T19:14:28.749694Z","iopub.status.idle":"2025-03-21T19:14:28.964508Z","shell.execute_reply.started":"2025-03-21T19:14:28.749668Z","shell.execute_reply":"2025-03-21T19:14:28.963801Z"}},"outputs":[{"name":"stdout","text":"Recommended Items: ['Movie_Ford v Ferrari', 'Music_5awljpWNO5TpXCyjpvCBbs', 'Music_29RiulWABWHcTRLkDqVCl1', 'Music_69Jv0CiMlrpfjh9N2WFkr0', 'Music_40o76YIOwDazc0h2QrZhWl']\n","output_type":"stream"}],"execution_count":14},{"id":"c0d801e1-e7d8-4e7c-b61c-5a1b4a45a8a7","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ed097c-1107-45dd-b25c-4b1761ef1067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T15:43:31.217576Z",
     "iopub.status.busy": "2025-03-21T15:43:31.217237Z",
     "iopub.status.idle": "2025-03-21T15:43:31.221129Z",
     "shell.execute_reply": "2025-03-21T15:43:31.220325Z",
     "shell.execute_reply.started": "2025-03-21T15:43:31.217544Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install datasets torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532d903d-7314-4b4d-9edd-072079f6c91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T17:09:13.593415Z",
     "iopub.status.busy": "2025-03-24T17:09:13.593231Z",
     "iopub.status.idle": "2025-03-24T17:09:13.597401Z",
     "shell.execute_reply": "2025-03-24T17:09:13.596472Z",
     "shell.execute_reply.started": "2025-03-24T17:09:13.593395Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0760698e-0f28-4262-9515-21169fc9fb9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:33:59.890664Z",
     "iopub.status.busy": "2025-03-21T18:33:59.890389Z",
     "iopub.status.idle": "2025-03-21T18:34:02.261961Z",
     "shell.execute_reply": "2025-03-21T18:34:02.261331Z",
     "shell.execute_reply.started": "2025-03-21T18:33:59.890642Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92df3aee-f6d6-405d-8574-334422b61f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:34:06.516405Z",
     "iopub.status.busy": "2025-03-21T18:34:06.515961Z",
     "iopub.status.idle": "2025-03-21T18:34:15.066687Z",
     "shell.execute_reply": "2025-03-21T18:34:15.065886Z",
     "shell.execute_reply.started": "2025-03-21T18:34:06.516381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c212799f7684575bd4934d2db5f8a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/850 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab2a144453a4ab2aff5b75f24fce36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "imdb_movies.csv:   0%|          | 0.00/6.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f58a9d69d341eca162b32c46ce9ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2fc7a3e7fc4b8883e48465b78400c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b28ff3c4e324ab28a9838289b4f0005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset.csv:   0%|          | 0.00/20.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c07bf430c07437ba545cb307feed89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/114000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd35782c10d44e48b1237cc5a250cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406a1b0aaf144cc895b1792f6cdaca62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "goodreads_data.csv:   0%|          | 0.00/11.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69740e66c501479db7cafecf31af0fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies = load_dataset(\"ExecuteAutomation/ImdbMovieDataSet\")\n",
    "music = load_dataset(\"maharshipandya/spotify-tracks-dataset\")\n",
    "books = load_dataset(\"Eitanli/goodreads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b274dda1-70d5-47b5-9dfa-82002c0bab8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:34:19.872973Z",
     "iopub.status.busy": "2025-03-21T18:34:19.872630Z",
     "iopub.status.idle": "2025-03-21T18:34:20.019089Z",
     "shell.execute_reply": "2025-03-21T18:34:20.018166Z",
     "shell.execute_reply.started": "2025-03-21T18:34:19.872950Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_df = movies['train'].to_pandas()\n",
    "music_df = music['train'].to_pandas()\n",
    "books_df = books['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16bb941-b116-4ad6-ae67-248d334c1945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:34:22.811870Z",
     "iopub.status.busy": "2025-03-21T18:34:22.811532Z",
     "iopub.status.idle": "2025-03-21T18:34:22.817180Z",
     "shell.execute_reply": "2025-03-21T18:34:22.816325Z",
     "shell.execute_reply.started": "2025-03-21T18:34:22.811841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['names', 'date_x', 'score', 'genre', 'overview', 'crew', 'orig_title',\n",
      "       'status', 'orig_lang', 'budget_x', 'revenue', 'country'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name',\n",
      "       'popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
      "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
      "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n",
      "       'track_genre'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'Book', 'Author', 'Description', 'Genres', 'Avg_Rating',\n",
      "       'Num_Ratings', 'URL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(movies_df.columns)\n",
    "print(music_df.columns)\n",
    "print(books_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62feff6-a507-4409-ae59-6e5727cd4f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:34:28.636253Z",
     "iopub.status.busy": "2025-03-21T18:34:28.635850Z",
     "iopub.status.idle": "2025-03-21T18:34:29.588861Z",
     "shell.execute_reply": "2025-03-21T18:34:29.587951Z",
     "shell.execute_reply.started": "2025-03-21T18:34:28.636218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Item_ID                        Title  \\\n",
      "0                    Movie_Creed III                    Creed III   \n",
      "1     Movie_Avatar: The Way of Water     Avatar: The Way of Water   \n",
      "2  Movie_The Super Mario Bros. Movie  The Super Mario Bros. Movie   \n",
      "3                      Movie_Mummies                       Momias   \n",
      "4                    Movie_Supercell                    Supercell   \n",
      "\n",
      "                                           Genre  \\\n",
      "0                                  Drama, Action   \n",
      "1             Science Fiction, Adventure, Action   \n",
      "2  Animation, Adventure, Family, Fantasy, Comedy   \n",
      "3  Animation, Comedy, Family, Adventure, Fantasy   \n",
      "4                                         Action   \n",
      "\n",
      "                                         Description  Popularity  \\\n",
      "0  After dominating the boxing world, Adonis Cree...        73.0   \n",
      "1  Set more than a decade after the events of the...        78.0   \n",
      "2  While working underground to fix a water main,...        76.0   \n",
      "3  Through a series of unfortunate events, three ...        70.0   \n",
      "4  Good-hearted teenager William always lived in ...        61.0   \n",
      "\n",
      "                                             Creator  Timestamp Item_Type  \n",
      "0  Michael B. Jordan, Adonis Creed, Tessa Thompso... 2023-03-02     Movie  \n",
      "1  Sam Worthington, Jake Sully, Zoe Saldaña, Neyt... 2022-12-15     Movie  \n",
      "2  Chris Pratt, Mario (voice), Anya Taylor-Joy, P... 2023-04-05     Movie  \n",
      "3  Óscar Barberán, Thut (voice), Ana Esther Albor... 2023-01-05     Movie  \n",
      "4  Skeet Ulrich, Roy Cameron, Anne Heche, Dr Quin... 2023-03-17     Movie  \n"
     ]
    }
   ],
   "source": [
    "# Assign unique Item_IDs\n",
    "movies_df[\"Item_ID\"] = \"Movie_\" + movies_df[\"names\"].astype(str)\n",
    "music_df[\"Item_ID\"] = \"Music_\" + music_df[\"track_id\"].astype(str)\n",
    "books_df[\"Item_ID\"] = \"Book_\" + books_df[\"Book\"].astype(str)\n",
    "\n",
    "# Standardizing Columns\n",
    "movies_df = movies_df[[\"Item_ID\", \"orig_title\", \"genre\", \"overview\", \"score\", \"crew\", \"date_x\"]]\n",
    "music_df = music_df[[\"Item_ID\", \"track_name\", \"track_genre\", \"popularity\", \"artists\"]]\n",
    "books_df = books_df[[\"Item_ID\", \"Book\", \"Genres\", \"Description\", \"Avg_Rating\", \"Author\"]]\n",
    "\n",
    "# Rename for consistency\n",
    "movies_df.rename(columns={\"orig_title\": \"Title\", \"genre\": \"Genre\", \"overview\": \"Description\", \"score\": \"Popularity\", \"crew\": \"Creator\", \"date_x\": \"Timestamp\"}, inplace=True)\n",
    "music_df.rename(columns={\"track_name\": \"Title\", \"track_genre\": \"Genre\", \"popularity\": \"Popularity\", \"artists\": \"Creator\"}, inplace=True)\n",
    "books_df.rename(columns={\"Book\": \"Title\", \"Genres\": \"Genre\", \"Description\": \"Description\", \"Avg_Rating\": \"Popularity\", \"Author\": \"Creator\"}, inplace=True)\n",
    "\n",
    "# Add Item_Type\n",
    "movies_df[\"Item_Type\"] = \"Movie\"\n",
    "music_df[\"Item_Type\"] = \"Music\"\n",
    "books_df[\"Item_Type\"] = \"Book\"\n",
    "\n",
    "# Handle missing timestamps (generate random timestamps)\n",
    "movies_df[\"Timestamp\"] = pd.to_datetime(movies_df[\"Timestamp\"], errors=\"coerce\")\n",
    "music_df[\"Timestamp\"] = pd.to_datetime(\"2024-03-17\")  # Static timestamp\n",
    "books_df[\"Timestamp\"] = pd.to_datetime(\"2024-03-17\")  # Static timestamp\n",
    "\n",
    "# Combine datasets\n",
    "merged_df = pd.concat([movies_df, music_df, books_df], ignore_index=True)\n",
    "\n",
    "# Save preprocessed dataset\n",
    "merged_df.to_csv(\"session_data.csv\", index=False)\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8227284-83fb-4cb5-bee5-23449522e1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:34:38.046053Z",
     "iopub.status.busy": "2025-03-21T18:34:38.045773Z",
     "iopub.status.idle": "2025-03-21T18:34:38.963288Z",
     "shell.execute_reply": "2025-03-21T18:34:38.962612Z",
     "shell.execute_reply.started": "2025-03-21T18:34:38.046034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simulating user sessions\n",
    "session_ids = np.random.randint(1000, 5000, size=len(merged_df))\n",
    "action_types = np.random.choice([\"Clicked\", \"Searched\", \"Scrolled\"], size=len(merged_df))\n",
    "\n",
    "merged_df[\"Session_ID\"] = session_ids\n",
    "merged_df[\"Action_Type\"] = action_types\n",
    "\n",
    "# Save session-based data\n",
    "merged_df.to_csv(\"session_events.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b80706-ceaa-4e12-afb4-807791e3cd2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:34:42.808626Z",
     "iopub.status.busy": "2025-03-21T18:34:42.808348Z",
     "iopub.status.idle": "2025-03-21T18:51:36.082218Z",
     "shell.execute_reply": "2025-03-21T18:51:36.081238Z",
     "shell.execute_reply.started": "2025-03-21T18:34:42.808604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-c741148c7e68>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n",
      "<ipython-input-8-c741148c7e68>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.690988540649414\n",
      "Epoch 2, Loss: 7.596072673797607\n",
      "Epoch 3, Loss: 7.072775840759277\n",
      "Epoch 4, Loss: 6.372457027435303\n",
      "Epoch 5, Loss: 5.28287935256958\n",
      "Epoch 6, Loss: 4.004252910614014\n",
      "Epoch 7, Loss: 2.8613224029541016\n",
      "Epoch 8, Loss: 1.953985571861267\n",
      "Epoch 9, Loss: 1.0319585800170898\n",
      "Epoch 10, Loss: 0.7213608622550964\n",
      "Epoch 11, Loss: 0.41617482900619507\n",
      "Epoch 12, Loss: 0.25872746109962463\n",
      "Epoch 13, Loss: 0.20532339811325073\n",
      "Epoch 14, Loss: 0.11697680503129959\n",
      "Epoch 15, Loss: 0.08248290419578552\n",
      "Epoch 16, Loss: 0.08017588406801224\n",
      "Epoch 17, Loss: 0.05788752809166908\n",
      "Epoch 18, Loss: 0.044767845422029495\n",
      "Epoch 19, Loss: 0.038895055651664734\n",
      "Epoch 20, Loss: 0.03399191424250603\n",
      "Epoch 21, Loss: 0.03168043494224548\n",
      "Epoch 22, Loss: 0.02802925743162632\n",
      "Epoch 23, Loss: 0.028693964704871178\n",
      "Epoch 24, Loss: 0.02787163481116295\n",
      "Epoch 25, Loss: 0.02221776731312275\n",
      "Epoch 26, Loss: 0.017336327582597733\n",
      "Epoch 27, Loss: 0.01764662377536297\n",
      "Epoch 28, Loss: 0.018843399360775948\n",
      "Epoch 29, Loss: 0.013296118937432766\n",
      "Epoch 30, Loss: 0.014882288873195648\n",
      "Epoch 31, Loss: 0.012950303964316845\n",
      "Epoch 32, Loss: 0.01074859406799078\n",
      "Epoch 33, Loss: 0.011737334541976452\n",
      "Epoch 34, Loss: 0.012340893037617207\n",
      "Epoch 35, Loss: 0.015351041220128536\n",
      "Epoch 36, Loss: 0.011723592877388\n",
      "Epoch 37, Loss: 0.010426000691950321\n",
      "Epoch 38, Loss: 0.006986949592828751\n",
      "Epoch 39, Loss: 0.00940189603716135\n",
      "Epoch 40, Loss: 0.006995514966547489\n",
      "Epoch 41, Loss: 0.006028181407600641\n",
      "Epoch 42, Loss: 0.010025842115283012\n",
      "Epoch 43, Loss: 0.010780985467135906\n",
      "Epoch 44, Loss: 0.005456212442368269\n",
      "Epoch 45, Loss: 0.012309588491916656\n",
      "Epoch 46, Loss: 0.007568041794002056\n",
      "Epoch 47, Loss: 0.005075974855571985\n",
      "Epoch 48, Loss: 0.007050555665045977\n",
      "Epoch 49, Loss: 0.008526364341378212\n",
      "Epoch 50, Loss: 0.009745242074131966\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load session data\n",
    "data = pd.read_csv(\"session_events.csv\")\n",
    "\n",
    "# Convert Item_IDs into unique numerical values\n",
    "item_vocab = {item: idx for idx, item in enumerate(set(data[\"Item_ID\"]))}\n",
    "inv_vocab = {idx: item for item, idx in item_vocab.items()}\n",
    "\n",
    "# Convert sessions into numerical sequences\n",
    "sessions = data.groupby(\"Session_ID\")[\"Item_ID\"].apply(lambda x: [item_vocab[i] for i in x]).tolist()\n",
    "\n",
    "# Dataset Class\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class SessionDataset(Dataset):\n",
    "    def __init__(self, sessions, max_length=50):\n",
    "        self.sessions = sessions\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sessions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        session = self.sessions[idx]\n",
    "        session_tensor = torch.tensor(session, dtype=torch.long)\n",
    "\n",
    "        # Pad sequences to the max length\n",
    "        if len(session_tensor) < self.max_length:\n",
    "            pad_size = self.max_length - len(session_tensor)\n",
    "            session_tensor = torch.cat([session_tensor, torch.zeros(pad_size, dtype=torch.long)])\n",
    "\n",
    "        return session_tensor[:-1], session_tensor[1:]  # Input & Target\n",
    "\n",
    "# Collate function to pad sequences dynamically in the DataLoader\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n",
    "    return inputs_padded, targets_padded\n",
    "\n",
    "\n",
    "# Define GRU Model\n",
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
    "        super(GRU4Rec, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out)\n",
    "\n",
    "# Training Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = SessionDataset(sessions)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = GRU4Rec(len(item_vocab)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for batch in dataloader:\n",
    "        #inputs, targets = batch\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1, len(item_vocab)), targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "#torch.save(model.state_dict(), \"session_rec_model.pth\")\n",
    "torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), \"session_rec_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c6b30b-275e-452d-93e2-5b5c3ae83d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:54:11.360782Z",
     "iopub.status.busy": "2025-03-21T18:54:11.360423Z",
     "iopub.status.idle": "2025-03-21T19:11:32.969220Z",
     "shell.execute_reply": "2025-03-21T19:11:32.968227Z",
     "shell.execute_reply.started": "2025-03-21T18:54:11.360754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-f2480953a093>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n",
      "<ipython-input-10-f2480953a093>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8.307071125696575\n",
      "Epoch 2, Loss: 7.65139435208033\n",
      "Epoch 3, Loss: 7.225096967485216\n",
      "Epoch 4, Loss: 6.392066531711155\n",
      "Epoch 5, Loss: 5.274069975292872\n",
      "Epoch 6, Loss: 4.047372151934911\n",
      "Epoch 7, Loss: 2.8272931954217335\n",
      "Epoch 8, Loss: 1.7609415338152932\n",
      "Epoch 9, Loss: 1.0468707964533852\n",
      "Epoch 10, Loss: 0.6365305544838072\n",
      "Epoch 11, Loss: 0.3960812318892706\n",
      "Epoch 12, Loss: 0.2561607233115605\n",
      "Epoch 13, Loss: 0.1735328539969429\n",
      "Epoch 14, Loss: 0.12308307441454085\n",
      "Epoch 15, Loss: 0.09184038166015868\n",
      "Epoch 16, Loss: 0.07152377128128022\n",
      "Epoch 17, Loss: 0.05786299740984326\n",
      "Epoch 18, Loss: 0.04808862211685332\n",
      "Epoch 19, Loss: 0.0411058192451795\n",
      "Epoch 20, Loss: 0.03562455198594502\n",
      "Epoch 21, Loss: 0.03134127413587911\n",
      "Epoch 22, Loss: 0.027880316068019186\n",
      "Epoch 23, Loss: 0.02512658458380472\n",
      "Epoch 24, Loss: 0.022715698277193403\n",
      "Epoch 25, Loss: 0.02078732555466039\n",
      "Epoch 26, Loss: 0.019079701590632634\n",
      "Epoch 27, Loss: 0.017627021519555933\n",
      "Epoch 28, Loss: 0.016315578970880734\n",
      "Epoch 29, Loss: 0.015163679148942705\n",
      "Epoch 30, Loss: 0.01414240003814773\n",
      "Epoch 31, Loss: 0.013237946311987582\n",
      "Epoch 32, Loss: 0.012442565626568265\n",
      "Epoch 33, Loss: 0.011717579637964567\n",
      "Epoch 34, Loss: 0.011094338024064662\n",
      "Epoch 35, Loss: 0.010450052393097726\n",
      "Epoch 36, Loss: 0.009911512985589012\n",
      "Epoch 37, Loss: 0.009392340283190448\n",
      "Epoch 38, Loss: 0.008968864892801595\n",
      "Epoch 39, Loss: 0.008532174848138339\n",
      "Epoch 40, Loss: 0.008135444565957028\n",
      "Epoch 41, Loss: 0.0077609774316587145\n",
      "Epoch 42, Loss: 0.007484903588654503\n",
      "Epoch 43, Loss: 0.007157610093672124\n",
      "Epoch 44, Loss: 0.006884828047265136\n",
      "Epoch 45, Loss: 0.006573760312878423\n",
      "Epoch 46, Loss: 0.006347248042445807\n",
      "Epoch 47, Loss: 0.006141512832116513\n",
      "Epoch 48, Loss: 0.005926008572772382\n",
      "Epoch 49, Loss: 0.005714294848047079\n",
      "Epoch 50, Loss: 0.005526850683732875\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Load session data\n",
    "data = pd.read_csv(\"session_events.csv\")\n",
    "\n",
    "# Convert Item_IDs into unique numerical values\n",
    "item_vocab = {item: idx for idx, item in enumerate(set(data[\"Item_ID\"]))}\n",
    "inv_vocab = {idx: item for item, idx in item_vocab.items()}\n",
    "\n",
    "# Convert sessions into numerical sequences\n",
    "sessions = data.groupby(\"Session_ID\")[\"Item_ID\"].apply(lambda x: [item_vocab[i] for i in x]).tolist()\n",
    "\n",
    "# Dataset Class\n",
    "class SessionDataset(Dataset):\n",
    "    def __init__(self, sessions, max_length=50):\n",
    "        self.sessions = sessions\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sessions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        session = self.sessions[idx]\n",
    "        session_tensor = torch.tensor(session, dtype=torch.long)\n",
    "\n",
    "        # Pad sequences to the max length\n",
    "        if len(session_tensor) < self.max_length:\n",
    "            pad_size = self.max_length - len(session_tensor)\n",
    "            session_tensor = torch.cat([session_tensor, torch.zeros(pad_size, dtype=torch.long)])\n",
    "\n",
    "        return session_tensor[:-1], session_tensor[1:]  # Input & Target\n",
    "\n",
    "# Collate function to pad sequences dynamically in the DataLoader\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n",
    "    return inputs_padded, targets_padded\n",
    "\n",
    "# Define GRU Model\n",
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
    "        super(GRU4Rec, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out)\n",
    "\n",
    "# Training Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = SessionDataset(sessions)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = GRU4Rec(len(item_vocab)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 5  # Number of epochs to wait before stopping\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1, len(item_vocab)), targets.view(-1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
    "\n",
    "    # Early Stopping Logic\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save best model\n",
    "        torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), \"best_session_rec_model.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve}/{patience} epochs.\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        early_stop = True\n",
    "        break  # Stop training\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), \"session_rec_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80dbdd5e-c19f-4964-aae7-da68b0614b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T19:13:00.498363Z",
     "iopub.status.busy": "2025-03-21T19:13:00.498082Z",
     "iopub.status.idle": "2025-03-21T19:13:01.060854Z",
     "shell.execute_reply": "2025-03-21T19:13:01.059982Z",
     "shell.execute_reply.started": "2025-03-21T19:13:00.498340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-962d09d94511>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_session_rec_model.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GRU4Rec(\n",
       "  (embedding): Embedding(109272, 128)\n",
       "  (gru): GRU(128, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=109272, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GRU4Rec(len(item_vocab)).to(device)\n",
    "\n",
    "# Load best trained weights\n",
    "model.load_state_dict(torch.load(\"best_session_rec_model.pth\", map_location=device))\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c35288-0ff2-41aa-90c8-ea47a65bc129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T19:13:07.144173Z",
     "iopub.status.busy": "2025-03-21T19:13:07.143888Z",
     "iopub.status.idle": "2025-03-21T19:13:07.150010Z",
     "shell.execute_reply": "2025-03-21T19:13:07.149233Z",
     "shell.execute_reply.started": "2025-03-21T19:13:07.144151Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def recommend_next_items(session, top_k=5):\n",
    "    \"\"\"\n",
    "    Given a session (list of Item_IDs), predict the next top-k recommended items.\n",
    "    \"\"\"\n",
    "    # Convert session items to numerical indices\n",
    "    session_numeric = [item_vocab[item] for item in session if item in item_vocab]\n",
    "    \n",
    "    if not session_numeric:\n",
    "        print(\"Error: None of the session items exist in the vocabulary.\")\n",
    "        return []\n",
    "    \n",
    "    # Convert to tensor and move to device\n",
    "    session_tensor = torch.tensor(session_numeric, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        output = model(session_tensor)  # Shape: (1, seq_len, vocab_size)\n",
    "\n",
    "    # Get the last output prediction\n",
    "    last_item_logits = output[:, -1, :]  # Shape: (1, vocab_size)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = F.softmax(last_item_logits, dim=-1)\n",
    "\n",
    "    # Get top-k recommended item indices\n",
    "    top_k_indices = torch.topk(probabilities, top_k, dim=-1).indices.squeeze(0).tolist()\n",
    "\n",
    "    # Convert indices back to Item_IDs\n",
    "    recommended_items = [inv_vocab[idx] for idx in top_k_indices]\n",
    "\n",
    "    return recommended_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1982af49-289d-4f00-8838-1274cb90e36f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T19:14:28.749694Z",
     "iopub.status.busy": "2025-03-21T19:14:28.749353Z",
     "iopub.status.idle": "2025-03-21T19:14:28.964508Z",
     "shell.execute_reply": "2025-03-21T19:14:28.963801Z",
     "shell.execute_reply.started": "2025-03-21T19:14:28.749668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Items: ['Movie_Ford v Ferrari', 'Music_5awljpWNO5TpXCyjpvCBbs', 'Music_29RiulWABWHcTRLkDqVCl1', 'Music_69Jv0CiMlrpfjh9N2WFkr0', 'Music_40o76YIOwDazc0h2QrZhWl']\n"
     ]
    }
   ],
   "source": [
    "# Example session (list of previously interacted Item_IDs)\n",
    "example_session = [\"Movie_Creed III\", \"Movie_Mummies\", \"Movie_Supercell\"]\n",
    "\n",
    "# Get top 5 recommendations\n",
    "recommendations = recommend_next_items(example_session, top_k=5)\n",
    "print(\"Recommended Items:\", recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d801e1-e7d8-4e7c-b61c-5a1b4a45a8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
